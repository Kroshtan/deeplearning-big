{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Deep_learning2.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"vfk-1xcUQ3Vh","colab_type":"code","outputId":"be1f023b-3b67-40f2-a49c-816e798313cf","executionInfo":{"status":"ok","timestamp":1560328122522,"user_tz":-120,"elapsed":8297,"user":{"displayName":"kupke2011@live.nl","photoUrl":"","userId":"05667716658323280448"}},"colab":{"base_uri":"https://localhost:8080/","height":330}},"source":["#Package needed for next code block\n","!pip3 install PyDrive"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting PyDrive\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/52/e0/0e64788e5dd58ce2d6934549676243dc69d982f198524be9b99e9c2a4fd5/PyDrive-1.3.1.tar.gz (987kB)\n","\u001b[K     |████████████████████████████████| 993kB 6.8MB/s \n","\u001b[?25hRequirement already satisfied: google-api-python-client>=1.2 in /usr/local/lib/python3.6/dist-packages (from PyDrive) (1.6.7)\n","Requirement already satisfied: oauth2client>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from PyDrive) (4.1.3)\n","Requirement already satisfied: PyYAML>=3.0 in /usr/local/lib/python3.6/dist-packages (from PyDrive) (3.13)\n","Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->PyDrive) (3.0.0)\n","Requirement already satisfied: six<2dev,>=1.6.1 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->PyDrive) (1.12.0)\n","Requirement already satisfied: httplib2<1dev,>=0.9.2 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->PyDrive) (0.11.3)\n","Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->PyDrive) (0.2.5)\n","Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->PyDrive) (0.4.5)\n","Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->PyDrive) (4.0)\n","Building wheels for collected packages: PyDrive\n","  Building wheel for PyDrive (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Stored in directory: /root/.cache/pip/wheels/fa/d2/9a/d3b6b506c2da98289e5d417215ce34b696db856643bad779f4\n","Successfully built PyDrive\n","Installing collected packages: PyDrive\n","Successfully installed PyDrive-1.3.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Bd8ockMwGQBV","colab_type":"code","colab":{}},"source":["!pip3 install tensorboardcolab"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wFuX3W13RDsG","colab_type":"code","colab":{}},"source":["#Code to authorize Colab to access Google Drive\n","import os\n","from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gljUxy3jRFnD","colab_type":"code","colab":{}},"source":["#Code for reading the data from Google Drive\n","#Non-augmented train data\n","download = drive.CreateFile({'id': '1-3R9ZN-yRXLmsm4oGmmuHM_REUwHEen3'})\n","download.GetContentFile('traindata.npy')\n","\n","#Augmented train data\n","download = drive.CreateFile({'id': '1VOUu67nZayC63KJ6DHvBYdYbtJVwgip2'})\n","download.GetContentFile('augmented_data_0.npy')\n","download = drive.CreateFile({'id': '1gtxZ_2e_OQKXppo0CQ0VBSYKDvfN2lWN'})\n","download.GetContentFile('augmented_data_1.npy')\n","download = drive.CreateFile({'id': '1EuUwJ_2zItjKpMx9EFfEXqeUzN6YcKay'})\n","download.GetContentFile('augmented_data_2.npy')\n","download = drive.CreateFile({'id': '1DspGBsieJRYI88EGbc_ctqIMKNX7mdN5'})\n","download.GetContentFile('augmented_data_3.npy')\n","download = drive.CreateFile({'id': '1mxI_xtHzovhgAKWVFQwDxT5623ZSgDU9'})\n","download.GetContentFile('augmented_data_4.npy')\n","download = drive.CreateFile({'id': '18hPceYSPrrmnnBo9GDO5NLWjBX6Vw2r7'})\n","download.GetContentFile('augmented_data_5.npy')\n","download = drive.CreateFile({'id': '1N__M6BKzQoU-56CcePPv6tAXRb5fT6N4'})\n","download.GetContentFile('augmented_data_6.npy')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"NVtH62wIG135","colab_type":"code","outputId":"08abbaf0-d5d8-4552-94e4-62a1903ad2ec","executionInfo":{"status":"error","timestamp":1559309828764,"user_tz":-120,"elapsed":1077,"user":{"displayName":"kupke2011@live.nl","photoUrl":"","userId":"05667716658323280448"}},"colab":{"base_uri":"https://localhost:8080/","height":185}},"source":["import tensorboardcolab\n"],"execution_count":0,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-22-90330e58ff50>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorboardcolab\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtbc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTensorBoardColab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'TensorBoardColab' is not defined"]}]},{"cell_type":"code","metadata":{"id":"dSDOip4GRHSG","colab_type":"code","cellView":"both","outputId":"e26084b9-8d47-4780-a34e-bafef5c6fbff","executionInfo":{"status":"error","timestamp":1559301164364,"user_tz":-120,"elapsed":17393,"user":{"displayName":"kupke2011@live.nl","photoUrl":"","userId":"05667716658323280448"}},"colab":{"base_uri":"https://localhost:8080/","height":1617}},"source":["#@title  { form-width: \"250px\" }\n","from __future__ import print_function, division\n","from keras.datasets import mnist\n","from keras.layers import Input, Dense, Reshape, Flatten, Dropout, Conv2D\n","from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n","from keras.layers import Conv2DTranspose, MaxPooling2D, Concatenate\n","from keras.layers.advanced_activations import LeakyReLU\n","from keras.layers.convolutional import UpSampling2D, Conv2D\n","from keras.models import Sequential, Model\n","from keras.optimizers import Adam\n","from keras.preprocessing.image import load_img, img_to_array, array_to_img\n","from keras.callbacks import TensorBoard\n","from PIL import Image\n","import PIL.ImageOps\n","import matplotlib.pyplot as plt\n","import os\n","import shutil\n","import glob, os\n","from PIL import Image\n","import PIL.ImageOps\n","import matplotlib.pyplot as plt\n","import sys\n","import numpy as np\n","\n","PREPARE_COLAB_DATA = False\n","RUN_ON_COLAB = True\n","NPY_SAVEFILE = 'traindata.npy'\n","IMAGE_DIR = 'images/'\n","TRAIN_ON_AUGMENTED = False\n","AUGMENTED_FILES = ['../augmented_data_0.npy', '../augmented_data_1.npy', '../augmented_data_2.npy',\n"," '../augmented_data_3.npy', '../augmented_data_4.npy', '../augmented_data_5.npy', '../augmented_data_6.npy', ]\n","\n","EPOCHS = 30000\n","BATCH_SIZE = 16\n","SAMPLE_INTERVAL = 100\n","\n","class GAN():\n","    def __init__(self):\n","        self.channels = 1\n","        self.latent_dim = 100\n","        rescale_factor = 32\n","\n","        optimizer = Adam(0.0001, 0.5)\n","\n","        self.logdir = \"./logs\"\n","        try:\n","          os.mkdir(self.logdir)\n","          print('Created log directory...')\n","        except:\n","          print('Log directory already exists!')\n","\n","        if not RUN_ON_COLAB:\n","            # Empty any old log directory\n","            for the_file in os.listdir(self.logdir):\n","                file_path = os.path.join(self.logdir, the_file)\n","                try:\n","                    if os.path.isfile(file_path):\n","                        os.unlink(file_path)\n","                    elif os.path.isdir(file_path): shutil.rmtree(file_path)\n","                except Exception as e:\n","                    print(e)\n","\n","            # Empty the generated image directory\n","            for the_file in os.listdir(\"./images\"):\n","                file_path = os.path.join(\"./images\", the_file)\n","                try:\n","                    if os.path.isfile(file_path):\n","                        os.unlink(file_path)\n","                    elif os.path.isdir(file_path): shutil.rmtree(file_path)\n","                except Exception as e:\n","                    print(e)\n","\n","\n","        # Load the dataset\n","        filelist = glob.glob(\"./source_imgs/*.jpg\")\n","        imgs = [Image.open(fname) for fname in filelist]\n","        if RUN_ON_COLAB:\n","            try:\n","                os.mkdir(IMAGE_DIR)\n","                print(\"Created output images directory...\")\n","            except:\n","                print(\"Output images directory already exists!\")\n","            if TRAIN_ON_AUGMENTED:\n","                self.X_train = np.load(AUGMENTED_FILES[0])\n","            else:\n","                self.X_train = np.load(NPY_SAVEFILE)\n","            print(self.X_train.shape)\n","            target_size = (max([x.shape[1] for x in self.X_train]), max([x.shape[0] for x in self.X_train]))\n","            self.img_shape = (target_size[1], target_size[0], self.channels)\n","        else:\n","            # Load the dataset\n","            filelist = glob.glob(\"./source_imgs/*.jpg\")\n","            imgs = [Image.open(fname) for fname in filelist]\n","\n","            self.target_size  = (max([x.size[0] for x in imgs]),\n","                                 max([x.size[1] for x in imgs]))\n","\n","            self.target_size = tuple([x//rescale_factor for x in self.target_size])\n","\n","            self.X_train = []\n","\n","            for img in imgs:\n","                old_size = img.size\n","                ratio = min(self.target_size[0]/old_size[0],\n","                            self.target_size[1]/old_size[1])\n","\n","                new_size = tuple([int(x*ratio) for x in old_size])\n","                img = img.resize(new_size, Image.ANTIALIAS)\n","                img = PIL.ImageOps.invert(img)\n","                new_img = Image.new(\"L\", self.target_size)\n","                new_img.paste(img, ((self.target_size[0]-new_size[0])//2,\n","                                    (self.target_size[1]-new_size[1])//2))\n","                self.X_train.append(new_img)\n","\n","            self.X_train = np.stack(self.X_train)\n","\n","            self.img_shape = (self.target_size[1],\n","                              self.target_size[0],\n","                              self.channels)\n","\n","            # Rescale -1 to 1\n","            self.X_train = self.X_train / 127.5 - 1.\n","            self.X_train = np.expand_dims(self.X_train, axis=3)\n","\n","        if PREPARE_COLAB_DATA:\n","            np.save(NPY_SAVEFILE, self.X_train)\n","            #quit()\n","\n","        # Build and compile the discriminator\n","        self.discriminator = self.build_discriminator()\n","        self.discriminator.compile(loss='binary_crossentropy',\n","            optimizer=optimizer,\n","            metrics=['accuracy'])\n","\n","        # Build the generator\n","        self.generator = self.build_generator()\n","\n","        # The generator takes noise as input and generates imgs\n","        z = Input(shape=(self.latent_dim,))\n","        img = self.generator(z)\n","\n","        # For the combined model we will only train the generator\n","        self.discriminator.trainable = False\n","\n","        # The discriminator takes generated images as input and determines validity\n","        validity = self.discriminator(img)\n","\n","        # The combined model  (stacked generator and discriminator)\n","        # Trains the generator to fool the discriminator\n","        self.combined = Model(z, validity)\n","        self.combined.compile(loss='binary_crossentropy', optimizer=optimizer)\n","\n","\n","    def build_generator(self):\n","\n","        inp = Input(shape=(self.latent_dim,))\n","\n","        layer1 = Dense(256,\n","                       input_shape=(self.latent_dim,),\n","                       activation='relu')(inp)\n","        bn1 = BatchNormalization(momentum=0.8)(layer1)\n","\n","        layer2 = Dense(512,\n","                       activation='relu')(bn1)\n","        bn2 = BatchNormalization(momentum=0.8)(layer2)\n","\n","        layer3 = Dense(1024,\n","                       activation='relu')(bn2)\n","        bn3 = BatchNormalization(momentum=0.8)(layer3)\n","\n","        layer4 = Dense(2056,\n","                       activation='relu')(bn3)\n","        bn4 = BatchNormalization(momentum=0.8)(layer4)\n","\n","        concat = Concatenate(axis=-1)([bn1,bn2, bn3, bn4])\n","\n","        pre_out = Dense(np.prod(self.img_shape), activation='tanh')(concat)\n","\n","        out = Reshape(target_shape=(self.img_shape))(pre_out)\n","\n","        model = Model(inputs=inp, outputs=out)\n","\n","        model.summary()\n","\n","        return model\n","\n","    def build_discriminator(self):\n","\n","        inp = Input(shape=self.img_shape)\n","\n","        conv1 = Conv2D(filters=8,\n","                       kernel_size=(4, 4),\n","                       activation='relu',\n","                       padding='same')(inp)\n","        mp1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n","\n","        cfc1 = Flatten()(conv1)\n","        cfc1 = Dense(128, activation='relu')(cfc1)\n","\n","        conv2 = Conv2D(filters=12,\n","                       kernel_size=(4, 4),\n","                       activation='relu',\n","                       padding='same')(mp1)\n","        mp2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n","\n","        cfc2 = Flatten()(conv2)\n","        cfc2 = Dense(128, activation='relu')(cfc2)\n","\n","        conv3 = Conv2D(filters=16,\n","                       kernel_size=(4, 4),\n","                       activation='relu',\n","                       padding='same')(mp2)\n","        mp3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n","\n","        cfc3 = Flatten()(conv3)\n","        cfc3 = Dense(128, activation='relu')(cfc3)\n","\n","        flatten = Flatten()(mp3)\n","\n","        flatten = Concatenate()([flatten, cfc1, cfc2, cfc3])\n","\n","        fc1 = Dense(512, activation='relu')(flatten)\n","        fc2 = Dense(512, activation='relu')(fc1)\n","\n","        out = Dense(1, activation='sigmoid')(fc2)\n","\n","        model = Model(inputs=inp, outputs=out)\n","        model.summary()\n","\n","        return model\n","\n","    def train(self, epochs, batch_size=1, sample_interval=50):\n","\n","        # Adversarial ground truths\n","        valid = np.ones((batch_size, 1))\n","        fake = np.zeros((batch_size, 1))\n","\n","        tensorboard = TensorBoard(log_dir=self.logdir)\n","        tensorboard.set_model(self.discriminator)\n","\n","        for idx in range(0, len(AUGMENTED_FILES)):\n","            for epoch in range(epochs):\n","\n","                # ---------------------\n","                #  Train Discriminator\n","                # ---------------------\n","\n","                # Select a random batch of images\n","                idx = np.random.randint(0, self.X_train.shape[0], batch_size)\n","                imgs = self.X_train[idx]\n","\n","                noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n","\n","                # Generate a batch of new images\n","                gen_imgs = self.generator.predict(noise)\n","\n","                if epoch == 0 or accuracy < 80:\n","                    # Train the discriminator\n","                    d_loss_real = self.discriminator.train_on_batch(imgs, valid)\n","                    d_loss_fake = self.discriminator.train_on_batch(gen_imgs, fake)\n","                    d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n","                else:\n","                    # Test the discriminator\n","                    d_loss_real = self.discriminator.test_on_batch(imgs, valid)\n","                    d_loss_fake = self.discriminator.test_on_batch(gen_imgs, fake)\n","                    d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n","\n","                accuracy = 100*d_loss[1]\n","\n","                # ---------------------\n","                #  Train Generator\n","                # ---------------------\n","                noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n","\n","                if epoch == 0 or accuracy > 20:\n","                    # Train the generator (to have the discriminator label samples as valid)\n","                    g_loss = self.combined.train_on_batch(noise, valid)\n","                else:\n","                    # Train the generator (to have the discriminator label samples as valid)\n","                    g_loss = self.combined.test_on_batch(noise, valid)\n","\n","                tensorboard.on_epoch_end(epoch, {'generator loss': g_loss, 'discriminator loss': d_loss[0], 'Accuracy': accuracy})\n","\n","                # Plot the progress\n","                if RUN_ON_COLAB:\n","                    if (epoch % 200) == 0:\n","                        print(f\"{epoch} [D loss: {d_loss[0]}, \" +\n","                      f\"acc.: {accuracy}%] [G loss: {g_loss}]\")\n","                else:\n","                    print(f\"{epoch} [D loss: {d_loss[0]:.3f}, \" +\n","                      f\"acc.: {accuracy:.2f}%] [G loss: {g_loss:.3f}]\")\n","\n","                # If at save interval => save generated image samples\n","                if epoch % sample_interval == 0:\n","                    self.sample_images(epoch)\n","            self.X_train = np.load(AUGMENTED_FILES[idx])\n","        tensorboard.on_train_end()\n","\n","    def sample_images(self, epoch):\n","        r, c = 5, 5\n","        noise = np.random.normal(0, 1, (r * c, self.latent_dim))\n","        gen_imgs = self.generator.predict(noise)\n","\n","        # Rescale images from [-1, 1] to [1, 0] (invert)\n","        gen_imgs = -0.5 * gen_imgs - 0.5\n","\n","        fig, axs = plt.subplots(r, c)\n","        cnt = 0\n","        for i in range(r):\n","            for j in range(c):\n","                axs[i,j].imshow(gen_imgs[cnt, :,:,0], cmap='gray')\n","                axs[i,j].axis('off')\n","                cnt += 1\n","        fig.savefig(IMAGE_DIR+\"%d.png\" % epoch)\n","        plt.close()\n","\n","\n","if __name__ == '__main__':\n","    gan = GAN()\n","    gan.train(epochs=EPOCHS, batch_size=BATCH_SIZE, sample_interval=SAMPLE_INTERVAL)\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Log directory already exists!\n","Created output images directory...\n","(510, 75, 96, 1)\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            (None, 75, 96, 1)    0                                            \n","__________________________________________________________________________________________________\n","conv2d_1 (Conv2D)               (None, 75, 96, 8)    136         input_1[0][0]                    \n","__________________________________________________________________________________________________\n","max_pooling2d_1 (MaxPooling2D)  (None, 37, 48, 8)    0           conv2d_1[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_2 (Conv2D)               (None, 37, 48, 12)   1548        max_pooling2d_1[0][0]            \n","__________________________________________________________________________________________________\n","max_pooling2d_2 (MaxPooling2D)  (None, 18, 24, 12)   0           conv2d_2[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_3 (Conv2D)               (None, 18, 24, 16)   3088        max_pooling2d_2[0][0]            \n","__________________________________________________________________________________________________\n","max_pooling2d_3 (MaxPooling2D)  (None, 9, 12, 16)    0           conv2d_3[0][0]                   \n","__________________________________________________________________________________________________\n","flatten_1 (Flatten)             (None, 57600)        0           conv2d_1[0][0]                   \n","__________________________________________________________________________________________________\n","flatten_2 (Flatten)             (None, 21312)        0           conv2d_2[0][0]                   \n","__________________________________________________________________________________________________\n","flatten_3 (Flatten)             (None, 6912)         0           conv2d_3[0][0]                   \n","__________________________________________________________________________________________________\n","flatten_4 (Flatten)             (None, 1728)         0           max_pooling2d_3[0][0]            \n","__________________________________________________________________________________________________\n","dense_1 (Dense)                 (None, 128)          7372928     flatten_1[0][0]                  \n","__________________________________________________________________________________________________\n","dense_2 (Dense)                 (None, 128)          2728064     flatten_2[0][0]                  \n","__________________________________________________________________________________________________\n","dense_3 (Dense)                 (None, 128)          884864      flatten_3[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_1 (Concatenate)     (None, 2112)         0           flatten_4[0][0]                  \n","                                                                 dense_1[0][0]                    \n","                                                                 dense_2[0][0]                    \n","                                                                 dense_3[0][0]                    \n","__________________________________________________________________________________________________\n","dense_4 (Dense)                 (None, 512)          1081856     concatenate_1[0][0]              \n","__________________________________________________________________________________________________\n","dense_5 (Dense)                 (None, 512)          262656      dense_4[0][0]                    \n","__________________________________________________________________________________________________\n","dense_6 (Dense)                 (None, 1)            513         dense_5[0][0]                    \n","==================================================================================================\n","Total params: 12,335,653\n","Trainable params: 12,335,653\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_2 (InputLayer)            (None, 100)          0                                            \n","__________________________________________________________________________________________________\n","dense_7 (Dense)                 (None, 256)          25856       input_2[0][0]                    \n","__________________________________________________________________________________________________\n","batch_normalization_1 (BatchNor (None, 256)          1024        dense_7[0][0]                    \n","__________________________________________________________________________________________________\n","dense_8 (Dense)                 (None, 512)          131584      batch_normalization_1[0][0]      \n","__________________________________________________________________________________________________\n","batch_normalization_2 (BatchNor (None, 512)          2048        dense_8[0][0]                    \n","__________________________________________________________________________________________________\n","dense_9 (Dense)                 (None, 1024)         525312      batch_normalization_2[0][0]      \n","__________________________________________________________________________________________________\n","batch_normalization_3 (BatchNor (None, 1024)         4096        dense_9[0][0]                    \n","__________________________________________________________________________________________________\n","dense_10 (Dense)                (None, 2056)         2107400     batch_normalization_3[0][0]      \n","__________________________________________________________________________________________________\n","batch_normalization_4 (BatchNor (None, 2056)         8224        dense_10[0][0]                   \n","__________________________________________________________________________________________________\n","concatenate_2 (Concatenate)     (None, 3848)         0           batch_normalization_1[0][0]      \n","                                                                 batch_normalization_2[0][0]      \n","                                                                 batch_normalization_3[0][0]      \n","                                                                 batch_normalization_4[0][0]      \n","__________________________________________________________________________________________________\n","dense_11 (Dense)                (None, 7200)         27712800    concatenate_2[0][0]              \n","__________________________________________________________________________________________________\n","reshape_1 (Reshape)             (None, 75, 96, 1)    0           dense_11[0][0]                   \n","==================================================================================================\n","Total params: 30,518,344\n","Trainable params: 30,510,648\n","Non-trainable params: 7,696\n","__________________________________________________________________________________________________\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.cast instead.\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n","  'Discrepancy between trainable weights and collected trainable'\n"],"name":"stderr"},{"output_type":"stream","text":["0 [D loss: 0.7325872182846069, acc.: 50.0%] [G loss: 0.49655619263648987]\n","200 [D loss: 0.30917873978614807, acc.: 87.5%] [G loss: 0.9201050400733948]\n","400 [D loss: 0.28617769479751587, acc.: 100.0%] [G loss: 3.981473207473755]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Tbia2zHZdFRU","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}