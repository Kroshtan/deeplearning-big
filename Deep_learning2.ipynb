{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Deep_learning2.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"vfk-1xcUQ3Vh","colab_type":"code","outputId":"ab7875aa-0e92-41dc-eb7d-cf9883775926","executionInfo":{"status":"ok","timestamp":1559302991247,"user_tz":-120,"elapsed":9079,"user":{"displayName":"kupke2011@live.nl","photoUrl":"","userId":"05667716658323280448"}},"colab":{"base_uri":"https://localhost:8080/","height":330}},"source":["#Package needed for next code block\n","!pip3 install PyDrive"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting PyDrive\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/52/e0/0e64788e5dd58ce2d6934549676243dc69d982f198524be9b99e9c2a4fd5/PyDrive-1.3.1.tar.gz (987kB)\n","\r\u001b[K     |▎                               | 10kB 15.6MB/s eta 0:00:01\r\u001b[K     |▋                               | 20kB 4.1MB/s eta 0:00:01\r\u001b[K     |█                               | 30kB 5.8MB/s eta 0:00:01\r\u001b[K     |█▎                              | 40kB 3.8MB/s eta 0:00:01\r\u001b[K     |█▋                              | 51kB 4.7MB/s eta 0:00:01\r\u001b[K     |██                              | 61kB 5.6MB/s eta 0:00:01\r\u001b[K     |██▎                             | 71kB 6.4MB/s eta 0:00:01\r\u001b[K     |██▋                             | 81kB 7.1MB/s eta 0:00:01\r\u001b[K     |███                             | 92kB 7.9MB/s eta 0:00:01\r\u001b[K     |███▎                            | 102kB 6.3MB/s eta 0:00:01\r\u001b[K     |███▋                            | 112kB 6.3MB/s eta 0:00:01\r\u001b[K     |████                            | 122kB 6.3MB/s eta 0:00:01\r\u001b[K     |████▎                           | 133kB 6.3MB/s eta 0:00:01\r\u001b[K     |████▋                           | 143kB 6.3MB/s eta 0:00:01\r\u001b[K     |█████                           | 153kB 6.3MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 163kB 6.3MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 174kB 6.3MB/s eta 0:00:01\r\u001b[K     |██████                          | 184kB 6.3MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 194kB 6.3MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 204kB 6.3MB/s eta 0:00:01\r\u001b[K     |███████                         | 215kB 6.3MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 225kB 6.3MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 235kB 6.3MB/s eta 0:00:01\r\u001b[K     |████████                        | 245kB 6.3MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 256kB 6.3MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 266kB 6.3MB/s eta 0:00:01\r\u001b[K     |█████████                       | 276kB 6.3MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 286kB 6.3MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 296kB 6.3MB/s eta 0:00:01\r\u001b[K     |██████████                      | 307kB 6.3MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 317kB 6.3MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 327kB 6.3MB/s eta 0:00:01\r\u001b[K     |███████████                     | 337kB 6.3MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 348kB 6.3MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 358kB 6.3MB/s eta 0:00:01\r\u001b[K     |████████████                    | 368kB 6.3MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 378kB 6.3MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 389kB 6.3MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 399kB 6.3MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 409kB 6.3MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 419kB 6.3MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 430kB 6.3MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 440kB 6.3MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 450kB 6.3MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 460kB 6.3MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 471kB 6.3MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 481kB 6.3MB/s eta 0:00:01\r\u001b[K     |████████████████                | 491kB 6.3MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 501kB 6.3MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 512kB 6.3MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 522kB 6.3MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 532kB 6.3MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 542kB 6.3MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 552kB 6.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 563kB 6.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 573kB 6.3MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 583kB 6.3MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 593kB 6.3MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 604kB 6.3MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 614kB 6.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 624kB 6.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 634kB 6.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 645kB 6.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 655kB 6.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 665kB 6.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 675kB 6.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 686kB 6.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 696kB 6.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 706kB 6.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 716kB 6.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 727kB 6.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 737kB 6.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 747kB 6.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 757kB 6.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 768kB 6.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 778kB 6.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 788kB 6.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 798kB 6.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 808kB 6.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 819kB 6.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 829kB 6.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 839kB 6.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 849kB 6.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 860kB 6.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 870kB 6.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 880kB 6.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 890kB 6.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 901kB 6.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 911kB 6.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 921kB 6.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 931kB 6.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 942kB 6.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 952kB 6.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 962kB 6.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 972kB 6.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 983kB 6.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 993kB 6.3MB/s \n","\u001b[?25hRequirement already satisfied: google-api-python-client>=1.2 in /usr/local/lib/python3.6/dist-packages (from PyDrive) (1.6.7)\n","Requirement already satisfied: oauth2client>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from PyDrive) (4.1.3)\n","Requirement already satisfied: PyYAML>=3.0 in /usr/local/lib/python3.6/dist-packages (from PyDrive) (3.13)\n","Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->PyDrive) (3.0.0)\n","Requirement already satisfied: httplib2<1dev,>=0.9.2 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->PyDrive) (0.11.3)\n","Requirement already satisfied: six<2dev,>=1.6.1 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->PyDrive) (1.12.0)\n","Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->PyDrive) (0.2.5)\n","Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->PyDrive) (0.4.5)\n","Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->PyDrive) (4.0)\n","Building wheels for collected packages: PyDrive\n","  Building wheel for PyDrive (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Stored in directory: /root/.cache/pip/wheels/fa/d2/9a/d3b6b506c2da98289e5d417215ce34b696db856643bad779f4\n","Successfully built PyDrive\n","Installing collected packages: PyDrive\n","Successfully installed PyDrive-1.3.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"wFuX3W13RDsG","colab_type":"code","colab":{}},"source":["#Code to authorize Colab to access Google Drive\n","import os\n","from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gljUxy3jRFnD","colab_type":"code","colab":{}},"source":["#Code for reading the data from Google Drive\n","#Train data\n","download = drive.CreateFile({'id': '1-3R9ZN-yRXLmsm4oGmmuHM_REUwHEen3'})\n","download.GetContentFile('traindata.npy')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"dSDOip4GRHSG","colab_type":"code","cellView":"both","outputId":"e91e35bb-33db-46e1-89ec-6f55bac90775","executionInfo":{"status":"error","timestamp":1559303998679,"user_tz":-120,"elapsed":369082,"user":{"displayName":"kupke2011@live.nl","photoUrl":"","userId":"05667716658323280448"}},"colab":{"base_uri":"https://localhost:8080/","height":2035}},"source":["#@title  { form-width: \"250px\" }\n","from __future__ import print_function, division\n","from keras.datasets import mnist\n","from keras.layers import Input, Dense, Reshape, Flatten, Dropout\n","from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n","from keras.layers.advanced_activations import LeakyReLU\n","from keras.layers.convolutional import UpSampling2D, Conv2D\n","from keras.models import Sequential, Model\n","from keras.optimizers import Adam\n","from keras.preprocessing.image import load_img, img_to_array, array_to_img\n","import glob, os\n","from PIL import Image\n","import PIL.ImageOps\n","import matplotlib.pyplot as plt\n","import sys\n","import numpy as np\n","\n","PREPARE_COLAB_DATA = False\n","RUN_ON_COLAB = True\n","NPY_SAVEFILE = 'traindata.npy'\n","IMAGE_DIR = 'images/'\n","\n","class GAN():\n","    def __init__(self):\n","        self.channels = 1\n","        self.latent_dim = 100\n","\n","        optimizer = Adam(0.0002, 0.5)\n","\n","        if RUN_ON_COLAB:\n","            try:\n","                os.mkdir(IMAGE_DIR)\n","                print(\"Created output images directory...\")\n","            except:\n","                print(\"Output images directory already exists!\")\n","\n","            self.channels = 1\n","            self.X_train = np.load(NPY_SAVEFILE)\n","            print(self.X_train.shape)\n","            target_size = (max([x.shape[1] for x in self.X_train]), max([x.shape[0] for x in self.X_train]))\n","            self.img_shape = (target_size[1], target_size[0], self.channels)\n","        else:\n","            # Load the dataset\n","            filelist = glob.glob(\"./source_imgs/*.jpg\")\n","            imgs = [Image.open(fname) for fname in filelist]\n","\n","            rescale_factor = 32\n","\n","            target_size  = (max([x.size[0] for x in imgs]),\n","                            max([x.size[1] for x in imgs]))\n","\n","            target_size = tuple([x//rescale_factor for x in target_size])\n","\n","            self.X_train = []\n","\n","            for img in imgs:\n","                old_size = img.size\n","                ratio = min(target_size[0]/old_size[0],\n","                            target_size[1]/old_size[1])\n","\n","                new_size = tuple([int(x*ratio) for x in old_size])\n","                img = img.resize(new_size, Image.ANTIALIAS)\n","                img = PIL.ImageOps.invert(img)\n","                new_img = Image.new(\"L\", target_size)\n","                new_img.paste(img, ((target_size[0]-new_size[0])//2,\n","                                    (target_size[1]-new_size[1])//2))\n","                self.X_train.append(new_img)\n","\n","            self.X_train = np.stack(self.X_train)\n","\n","            self.img_shape = (target_size[1],\n","                              target_size[0],\n","                              self.channels)\n","\n","            # Rescale -1 to 1\n","            self.X_train = self.X_train / 127.5 - 1.\n","            self.X_train = np.expand_dims(self.X_train, axis=3)\n","\n","        if PREPARE_COLAB_DATA:\n","            np.save(NPY_SAVEFILE, self.X_train)\n","            #quit()\n","\n","        # Build and compile the discriminator\n","        self.discriminator = self.build_discriminator()\n","        self.discriminator.compile(loss='binary_crossentropy',\n","            optimizer=optimizer,\n","            metrics=['accuracy'])\n","\n","        # Build the generator\n","        self.generator = self.build_generator()\n","\n","        # The generator takes noise as input and generates imgs\n","        z = Input(shape=(self.latent_dim,))\n","        img = self.generator(z)\n","\n","        # For the combined model we will only train the generator\n","        self.discriminator.trainable = False\n","\n","        # The discriminator takes generated images as input and determines validity\n","        validity = self.discriminator(img)\n","\n","        # The combined model  (stacked generator and discriminator)\n","        # Trains the generator to fool the discriminator\n","        self.combined = Model(z, validity)\n","        self.combined.compile(loss='binary_crossentropy', optimizer=optimizer)\n","\n","\n","    def build_generator(self):\n","\n","        model = Sequential()\n","\n","        model.add(Dense(256, input_dim=self.latent_dim))\n","        model.add(LeakyReLU(alpha=0.2))\n","        model.add(BatchNormalization(momentum=0.8))\n","        model.add(Dense(512))\n","        model.add(LeakyReLU(alpha=0.2))\n","        model.add(BatchNormalization(momentum=0.8))\n","        model.add(Dense(1024))\n","        model.add(LeakyReLU(alpha=0.2))\n","        model.add(BatchNormalization(momentum=0.8))\n","        model.add(Dense(np.prod(self.img_shape), activation='tanh'))\n","        model.add(Reshape(self.img_shape))\n","\n","        model.summary()\n","\n","        noise = Input(shape=(self.latent_dim,))\n","        img = model(noise)\n","\n","        return Model(noise, img)\n","\n","    def build_discriminator(self):\n","\n","        model = Sequential()\n","\n","        model.add(Flatten(input_shape=self.img_shape))\n","        model.add(Dense(512))\n","        model.add(LeakyReLU(alpha=0.2))\n","        model.add(Dense(256))\n","        model.add(LeakyReLU(alpha=0.2))\n","        model.add(Dense(1, activation='sigmoid'))\n","        model.summary()\n","\n","        img = Input(shape=self.img_shape)\n","        validity = model(img)\n","\n","        return Model(img, validity)\n","\n","    def train(self, epochs, batch_size=128, sample_interval=50):\n","\n","        # Adversarial ground truths\n","        valid = np.ones((batch_size, 1))\n","        fake = np.zeros((batch_size, 1))\n","\n","        for epoch in range(epochs):\n","\n","            # ---------------------\n","            #  Train Discriminator\n","            # ---------------------\n","\n","            # Select a random batch of images\n","            idx = np.random.randint(0, self.X_train.shape[0], batch_size)\n","            imgs = self.X_train[idx]\n","\n","            noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n","\n","            # Generate a batch of new images\n","            gen_imgs = self.generator.predict(noise)\n","\n","            # Train the discriminator\n","            d_loss_real = self.discriminator.train_on_batch(imgs, valid)\n","            d_loss_fake = self.discriminator.train_on_batch(gen_imgs, fake)\n","            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n","\n","            # ---------------------\n","            #  Train Generator\n","            # ---------------------\n","\n","            noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n","\n","            # Train the generator (to have the discriminator label samples as valid)\n","            g_loss = self.combined.train_on_batch(noise, valid)\n","\n","            # Plot the progress\n","            if RUN_ON_COLAB:\n","                if (epoch % 200) == 0:\n","                    print (\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss))\n","            else:\n","                print (\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss))\n","\n","            # If at save interval => save generated image samples\n","            if epoch % sample_interval == 0:\n","                self.sample_images(epoch)\n","\n","    def sample_images(self, epoch):\n","        r, c = 5, 5\n","        noise = np.random.normal(0, 1, (r * c, self.latent_dim))\n","        gen_imgs = self.generator.predict(noise)\n","\n","        # Rescale images 0 - 1\n","        gen_imgs = 0.5 * gen_imgs + 0.5\n","\n","        fig, axs = plt.subplots(r, c)\n","        cnt = 0\n","        for i in range(r):\n","            for j in range(c):\n","                axs[i,j].imshow(gen_imgs[cnt, :,:,0], cmap='gray')\n","                axs[i,j].axis('off')\n","                cnt += 1\n","        fig.savefig(IMAGE_DIR+\"%d.png\" % epoch)\n","        plt.close()\n","\n","\n","if __name__ == '__main__':\n","    gan = GAN()\n","    gan.train(epochs=30000, batch_size=32, sample_interval=200)\n"],"execution_count":9,"outputs":[{"output_type":"stream","text":["Output images directory already exists!\n","(510, 75, 96, 1)\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","flatten_4 (Flatten)          (None, 7200)              0         \n","_________________________________________________________________\n","dense_22 (Dense)             (None, 512)               3686912   \n","_________________________________________________________________\n","leaky_re_lu_16 (LeakyReLU)   (None, 512)               0         \n","_________________________________________________________________\n","dense_23 (Dense)             (None, 256)               131328    \n","_________________________________________________________________\n","leaky_re_lu_17 (LeakyReLU)   (None, 256)               0         \n","_________________________________________________________________\n","dense_24 (Dense)             (None, 1)                 257       \n","=================================================================\n","Total params: 3,818,497\n","Trainable params: 3,818,497\n","Non-trainable params: 0\n","_________________________________________________________________\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_25 (Dense)             (None, 256)               25856     \n","_________________________________________________________________\n","leaky_re_lu_18 (LeakyReLU)   (None, 256)               0         \n","_________________________________________________________________\n","batch_normalization_10 (Batc (None, 256)               1024      \n","_________________________________________________________________\n","dense_26 (Dense)             (None, 512)               131584    \n","_________________________________________________________________\n","leaky_re_lu_19 (LeakyReLU)   (None, 512)               0         \n","_________________________________________________________________\n","batch_normalization_11 (Batc (None, 512)               2048      \n","_________________________________________________________________\n","dense_27 (Dense)             (None, 1024)              525312    \n","_________________________________________________________________\n","leaky_re_lu_20 (LeakyReLU)   (None, 1024)              0         \n","_________________________________________________________________\n","batch_normalization_12 (Batc (None, 1024)              4096      \n","_________________________________________________________________\n","dense_28 (Dense)             (None, 7200)              7380000   \n","_________________________________________________________________\n","reshape_4 (Reshape)          (None, 75, 96, 1)         0         \n","=================================================================\n","Total params: 8,069,920\n","Trainable params: 8,066,336\n","Non-trainable params: 3,584\n","_________________________________________________________________\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.cast instead.\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n","  'Discrepancy between trainable weights and collected trainable'\n"],"name":"stderr"},{"output_type":"stream","text":["0 [D loss: 0.607619, acc.: 48.44%] [G loss: 0.609152]\n","200 [D loss: 0.324361, acc.: 82.81%] [G loss: 2.994296]\n","400 [D loss: 0.458433, acc.: 59.38%] [G loss: 0.743674]\n","600 [D loss: 0.528542, acc.: 56.25%] [G loss: 0.792101]\n","800 [D loss: 0.558639, acc.: 54.69%] [G loss: 0.789294]\n","1000 [D loss: 0.565533, acc.: 62.50%] [G loss: 0.754290]\n","1200 [D loss: 8.059048, acc.: 50.00%] [G loss: 16.118095]\n","1400 [D loss: 8.059048, acc.: 50.00%] [G loss: 16.118095]\n","1600 [D loss: 8.059048, acc.: 50.00%] [G loss: 16.118095]\n","1800 [D loss: 8.059048, acc.: 50.00%] [G loss: 16.118095]\n","2000 [D loss: 8.059048, acc.: 50.00%] [G loss: 16.118095]\n","2200 [D loss: 8.059048, acc.: 50.00%] [G loss: 16.118095]\n","2400 [D loss: 8.059048, acc.: 50.00%] [G loss: 16.118095]\n","2600 [D loss: 8.059048, acc.: 50.00%] [G loss: 16.118095]\n","2800 [D loss: 8.059048, acc.: 50.00%] [G loss: 16.118095]\n","3000 [D loss: 8.059048, acc.: 50.00%] [G loss: 16.118095]\n","3200 [D loss: 8.059048, acc.: 50.00%] [G loss: 16.118095]\n","3400 [D loss: 8.059048, acc.: 50.00%] [G loss: 16.118095]\n","3600 [D loss: 8.059048, acc.: 50.00%] [G loss: 16.118095]\n","3800 [D loss: 8.059048, acc.: 50.00%] [G loss: 16.118095]\n","4000 [D loss: 8.059048, acc.: 50.00%] [G loss: 16.118095]\n","4200 [D loss: 8.059048, acc.: 50.00%] [G loss: 16.118095]\n","4400 [D loss: 8.059048, acc.: 50.00%] [G loss: 16.118095]\n","4600 [D loss: 8.059048, acc.: 50.00%] [G loss: 16.118095]\n","4800 [D loss: 8.059048, acc.: 50.00%] [G loss: 16.118095]\n","5000 [D loss: 8.059048, acc.: 50.00%] [G loss: 16.118095]\n","5200 [D loss: 8.059048, acc.: 50.00%] [G loss: 16.118095]\n","5400 [D loss: 8.059048, acc.: 50.00%] [G loss: 16.118095]\n","5600 [D loss: 8.059048, acc.: 50.00%] [G loss: 16.118095]\n","5800 [D loss: 8.059048, acc.: 50.00%] [G loss: 16.118095]\n","6000 [D loss: 8.059048, acc.: 50.00%] [G loss: 16.118095]\n","6200 [D loss: 8.059048, acc.: 50.00%] [G loss: 16.118095]\n","6400 [D loss: 8.059048, acc.: 50.00%] [G loss: 16.118095]\n","6600 [D loss: 8.059048, acc.: 50.00%] [G loss: 16.118095]\n","6800 [D loss: 8.059048, acc.: 50.00%] [G loss: 16.118095]\n","7000 [D loss: 8.059048, acc.: 50.00%] [G loss: 16.118095]\n","7200 [D loss: 8.059048, acc.: 50.00%] [G loss: 16.118095]\n","7400 [D loss: 8.059048, acc.: 50.00%] [G loss: 16.118095]\n","7600 [D loss: 8.059048, acc.: 50.00%] [G loss: 16.118095]\n","7800 [D loss: 8.059048, acc.: 50.00%] [G loss: 16.118095]\n","8000 [D loss: 8.059048, acc.: 50.00%] [G loss: 16.118095]\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-edef6641cf13>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0mgan\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGAN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m     \u001b[0mgan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_interval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-9-edef6641cf13>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, epochs, batch_size, sample_interval)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0;31m# Generate a batch of new images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m             \u001b[0mgen_imgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m             \u001b[0;31m# Train the discriminator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1167\u001b[0m                                             \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m                                             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1169\u001b[0;31m                                             steps=steps)\n\u001b[0m\u001b[1;32m   1170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1171\u001b[0m     def train_on_batch(self, x, y,\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mpredict_loop\u001b[0;34m(model, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m    292\u001b[0m                 \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    295\u001b[0m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]}]}