{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Deep_learning2.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"vfk-1xcUQ3Vh","colab_type":"code","outputId":"02e89c73-03a9-4093-b5e4-4c13f6ec5317","executionInfo":{"status":"ok","timestamp":1561970437952,"user_tz":-120,"elapsed":6050,"user":{"displayName":"kupke2011@live.nl","photoUrl":"","userId":"05667716658323280448"}},"colab":{"base_uri":"https://localhost:8080/","height":382}},"source":["#Package needed for next code block\n","!pip3 install PyDrive"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting PyDrive\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/52/e0/0e64788e5dd58ce2d6934549676243dc69d982f198524be9b99e9c2a4fd5/PyDrive-1.3.1.tar.gz (987kB)\n","\u001b[K     |████████████████████████████████| 993kB 2.8MB/s \n","\u001b[?25hRequirement already satisfied: google-api-python-client>=1.2 in /usr/local/lib/python3.6/dist-packages (from PyDrive) (1.7.9)\n","Requirement already satisfied: oauth2client>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from PyDrive) (4.1.3)\n","Requirement already satisfied: PyYAML>=3.0 in /usr/local/lib/python3.6/dist-packages (from PyDrive) (3.13)\n","Requirement already satisfied: httplib2<1dev,>=0.9.2 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->PyDrive) (0.11.3)\n","Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->PyDrive) (3.0.0)\n","Requirement already satisfied: six<2dev,>=1.6.1 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->PyDrive) (1.12.0)\n","Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->PyDrive) (0.0.3)\n","Requirement already satisfied: google-auth>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->PyDrive) (1.4.2)\n","Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->PyDrive) (0.2.5)\n","Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->PyDrive) (0.4.5)\n","Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->PyDrive) (4.0)\n","Requirement already satisfied: cachetools>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.4.1->google-api-python-client>=1.2->PyDrive) (3.1.1)\n","Building wheels for collected packages: PyDrive\n","  Building wheel for PyDrive (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Stored in directory: /root/.cache/pip/wheels/fa/d2/9a/d3b6b506c2da98289e5d417215ce34b696db856643bad779f4\n","Successfully built PyDrive\n","Installing collected packages: PyDrive\n","Successfully installed PyDrive-1.3.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"wFuX3W13RDsG","colab_type":"code","colab":{}},"source":["#Code to authorize Colab to access Google Drive\n","import os\n","from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gljUxy3jRFnD","colab_type":"code","colab":{}},"source":["#Code for reading the data from Google Drive\n","#Non-augmented train data\n","download = drive.CreateFile({'id': '1-3R9ZN-yRXLmsm4oGmmuHM_REUwHEen3'})\n","download.GetContentFile('traindata.npy')\n","\n","#Augmented train data\n","download = drive.CreateFile({'id': '1aVjdTfLfkpL5EEAO3MQgXh69XqATCzvI'})\n","download.GetContentFile('robin_data_0.npy')\n","\n","download = drive.CreateFile({'id': '1xL0x8M9zmHkjvbAc8gf8R8JKYl_t_Gdu'})\n","download.GetContentFile('complex_data_0.npy')\n","\n","download = drive.CreateFile({'id': '1bbwjuDP7lYFDtF11QJ2QswEtLPpYGZYD'})\n","download.GetContentFile('robin_small.npy')\n","\n","download = drive.CreateFile({'id': '11b7WwYXKAGE5mt5r6lBPgwZR4K7csKrV'})\n","download.GetContentFile('robin_train.npy')\n","\n","download = drive.CreateFile({'id': '1Sjx06gAnJt0onnq5YSRQeKXaVkD5NP9z'})\n","download.GetContentFile('complex_train.npy')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"dSDOip4GRHSG","colab_type":"code","cellView":"both","outputId":"aa9aaa4e-f6d4-4544-8ba9-627b8ca5d6e3","executionInfo":{"status":"error","timestamp":1561975302554,"user_tz":-120,"elapsed":669443,"user":{"displayName":"kupke2011@live.nl","photoUrl":"","userId":"05667716658323280448"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["from __future__ import print_function, division\n","from keras.layers import Input, Dense, Reshape, Flatten, Conv2D, Activation\n","from keras.layers import MaxPooling2D, Concatenate, LeakyReLU, Conv2DTranspose\n","from keras.layers import Dropout\n","from keras.models import Model\n","from keras.optimizers import Adam\n","from keras.callbacks import TensorBoard\n","import matplotlib.pyplot as plt\n","import os\n","import shutil\n","import numpy as np\n","from os import mkdir\n","from os.path import isdir, abspath\n","\n","ROBINPATH = abspath(\"./ROBIN\")\n","COMPLEXPATH = abspath(\"./Dataset_complex\")\n","#OUTPATH = abspath(\"./augmented\")\n","train_robin = 'robin_train.npy'\n","train_complex = 'complex_train.npy'\n","\n","RESIZE_FACTOR = 32\n","TRAIN_ON_ROBIN = True\n","TRAIN_ON_COMPLEX = False\n","\n","NPY_SAVEFILE = 'traindata.npy'\n","IMAGE_DIR = 'images/'\n","LOG_DIR = './logs'\n","\n","EPOCHS = 1000000\n","BATCH_SIZE = 1\n","LEARNING_RATE = 1e-5\n","DECAY = 0\n","SAMPLE_INTERVAL = 50\n","\n","\n","class GAN():\n","    def __init__(self):\n","        self.latent_dim = (5, 5)\n","        #random_file = os.path.join(OUTPATH, os.listdir(OUTPATH)[0])\n","        self.img_size = np.load(train_robin, allow_pickle=True)[0].shape\n","        self.img_size += (1,)  # add color channel for conv layers\n","\n","        #self.this_npy_num_imgs = os.path.join(OUTPATH, os.listdir(OUTPATH)[0])\n","        self.this_npy_num_imgs = np.load(train_robin, allow_pickle=True)\n","        self.this_npy_num_imgs = self.this_npy_num_imgs.shape[0]\n","\n","        optimizer = Adam(LEARNING_RATE, decay=DECAY)\n","\n","        # Empty any old log directory\n","        if os.path.exists(LOG_DIR):\n","            shutil.rmtree(LOG_DIR)\n","            print(\"Removed old log directory.\")\n","\n","        os.mkdir(LOG_DIR)\n","        print('Created new log directory.')\n","\n","        # Empty any old image directory\n","        if os.path.exists(IMAGE_DIR):\n","            shutil.rmtree(IMAGE_DIR)\n","            print(\"Removed old image directory.\")\n","\n","        os.mkdir(IMAGE_DIR)\n","        print('Created new image directory.')\n","\n","        # Empty the generated image directory\n","        for the_file in os.listdir(IMAGE_DIR):\n","            file_path = os.path.join(IMAGE_DIR, the_file)\n","            try:\n","                if os.path.isfile(file_path):\n","                    os.unlink(file_path)\n","                elif os.path.isdir(file_path):\n","                    shutil.rmtree(file_path)\n","            except Exception as e:\n","                print(e)\n","\n","        # Build and compile the discriminator\n","        self.discriminator = self.build_discriminator()\n","        self.discriminator.summary()\n","        self.discriminator.compile(loss='binary_crossentropy',\n","                                   optimizer=optimizer,\n","                                   metrics=['accuracy'])\n","\n","        # Build the generator\n","        self.generator = self.build_generator()\n","\n","        # The generator takes noise as input and generates imgs\n","        z = Input(shape=self.latent_dim)\n","        img = self.generator(z)\n","\n","        # For the combined model we will only train the generator\n","        self.discriminator.trainable = False\n","\n","        # Discriminator takes generated images as input and determines validity\n","        validity = self.discriminator(img)\n","\n","        # The combined model (stacked generator and discriminator)\n","        # Trains the generator to fool the discriminator\n","        self.combined = Model(z, validity)\n","        self.combined.compile(loss='binary_crossentropy', optimizer=optimizer)\n","\n","    def build_generator(self):\n","\n","        n_filts = (32, 16)\n","        kernel_sizes = (8, 4)\n","\n","        inp = Input(shape=self.latent_dim)\n","\n","        layer1 = Flatten()(inp)\n","\n","        layer1 = Dense(units=n_filts[0] * np.prod(self.img_size))(layer1)\n","        layer1 = Dropout(rate=0.1)(layer1)\n","\n","        layer1 = Reshape(target_shape=(self.img_size[0],\n","                                       self.img_size[1],\n","                                       n_filts[0]))(layer1)\n","\n","        for i in range(min(len(n_filts), len(kernel_sizes))):\n","            layer1 = Conv2DTranspose(filters=n_filts[i],\n","                                     kernel_size=kernel_sizes[i],\n","                                     padding=\"same\")(layer1)\n","\n","        layer1 = Conv2DTranspose(filters=1,\n","                                 kernel_size=3,\n","                                 padding=\"same\")(layer1)\n","\n","        out = Reshape(target_shape=self.img_size)(layer1)\n","        out = Activation('tanh')(layer1)\n","\n","        model = Model(inputs=inp, outputs=out)\n","\n","        # model.summary()\n","\n","        return model\n","\n","    def build_discriminator(self):\n","\n","        d_in = Input(shape=self.img_size)\n","\n","        d = Conv2D(filters=12,\n","                   kernel_size=10,\n","                   activation='relu',\n","                   padding='same')(d_in)\n","\n","        d = Dense(units=512, activation='relu')(d)\n","\n","        d = Dense(units=1, activation='tanh')(d)\n","\n","        model = Model(inputs=d_in, outputs=d)\n","\n","        model.summary()\n","\n","        return model\n","\n","    def train(self, epochs, batch_size=BATCH_SIZE, sample_interval=50):\n","\n","        tensorboard = TensorBoard(log_dir=LOG_DIR)\n","        tensorboard.set_model(self.discriminator)\n","\n","        for epoch in range(epochs):\n","\n","            # ---------------------\n","            #  Train Discriminator\n","            # ---------------------\n","\n","            # Detect batch size in npys\n","\n","            batch_size = min(self.this_npy_num_imgs, batch_size)\n","\n","            idx = np.random.randint(0, self.this_npy_num_imgs-1, batch_size)\n","\n","            # Select a random batch of images\n","            #self.X_train = os.path.join(OUTPATH, np.random.choice(os.listdir(OUTPATH)))\n","            self.X_train = np.load(train_robin, allow_pickle=True)\n","            self.X_train = self.X_train[idx]\n","            self.X_train = np.expand_dims(self.X_train, axis=3)\n","            self.X_train = self.X_train / (255/2) - 1\n","\n","            noise = np.random.normal(-1, 1, ((batch_size,) + self.latent_dim))\n","\n","            # Adversarial ground truths\n","            valid = np.ones(self.X_train.shape)\n","            fake = np.zeros(self.X_train.shape)\n","\n","            # Generate a batch of new images\n","            gen_imgs = self.generator.predict(noise)\n","\n","            if epoch == 0 or accuracy < 80:\n","                # Train the discriminator\n","                d_loss_real = self.discriminator.train_on_batch(self.X_train,\n","                                                                valid)\n","                d_loss_fake = self.discriminator.train_on_batch(gen_imgs, fake)\n","            else:\n","                # Test the discriminator\n","                d_loss_real = self.discriminator.test_on_batch(self.X_train,\n","                                                               valid)\n","                d_loss_fake = self.discriminator.test_on_batch(gen_imgs, fake)\n","\n","            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n","\n","            accuracy = 100*d_loss[1]\n","\n","            # ---------------------\n","            #  Train Generator\n","            # ---------------------\n","            noise = np.random.normal(-1, 1, ((batch_size,) + self.latent_dim))\n","\n","            if epoch == 0 or accuracy > 20:\n","                # Train the generator (to have the discriminator label samples\n","                # as valid)\n","                g_loss = self.combined.train_on_batch(noise, valid)\n","            else:\n","                # Train the generator (to have the discriminator label samples\n","                # as valid)\n","                g_loss = self.combined.test_on_batch(noise, valid)\n","\n","            tensorboard.on_epoch_end(epoch, {'generator loss': g_loss,\n","                                             'discriminator loss': d_loss[0],\n","                                             'Accuracy': accuracy,\n","                                             'Comb. loss': g_loss + d_loss[0]})\n","\n","            # If at save interval => save generated image samples\n","            if epoch % sample_interval == 0:\n","                print(f\"@ {epoch:{len(str(EPOCHS))}}:\\t\"\n","                      f\"Accuracy: {int(accuracy):3}%\\t\"\n","                      f\"G-Loss: {g_loss:6.3f}\\t\"\n","                      f\"D-Loss: {d_loss[0]:6.3f}\\t\"\n","                      f\"Combined: {g_loss+d_loss[0]:6.3f}\")\n","                self.sample_images(epoch)\n","\n","        tensorboard.on_train_end(tensorboard)\n","        self.discriminator.save('discriminator.h5')\n","        self.generator.save('generator.h5')\n","\n","    def sample_images(self, epoch):\n","        r = 3\n","        noise = np.random.normal(-1, 1, ((r,) + self.latent_dim))\n","        gen_imgs = self.generator.predict(noise)\n","\n","        # Select a random image\n","        #real_imgs = os.path.join(OUTPATH, np.random.choice(os.listdir(OUTPATH)))\n","        real_imgs = np.load(train_robin, allow_pickle=True)\n","        real_imgs = real_imgs[np.random.randint(0, BATCH_SIZE*8), :, :]\n","\n","        fig, axs = plt.subplots(r)\n","\n","        axs[0].imshow(real_imgs, cmap='gray')\n","        axs[0].axis('off')\n","\n","        cnt = 0\n","        for i in range(r-1):\n","            axs[i+1].imshow(gen_imgs[cnt, :, :, 0], cmap='gray')\n","            axs[i+1].axis('off')\n","            cnt += 1\n","\n","        fig.savefig(IMAGE_DIR+\"%d.png\" % epoch)\n","        plt.close()\n","\n","\n","if __name__ == '__main__':\n","    # Train the GAN\n","    gan = GAN()\n","    gan.train(epochs=EPOCHS, sample_interval=SAMPLE_INTERVAL)\n"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Removed old log directory.\n","Created new log directory.\n","Removed old image directory.\n","Created new image directory.\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_7 (InputLayer)         (None, 230, 230, 1)       0         \n","_________________________________________________________________\n","conv2d_4 (Conv2D)            (None, 230, 230, 12)      1212      \n","_________________________________________________________________\n","dense_12 (Dense)             (None, 230, 230, 512)     6656      \n","_________________________________________________________________\n","dense_13 (Dense)             (None, 230, 230, 1)       513       \n","=================================================================\n","Total params: 8,381\n","Trainable params: 8,381\n","Non-trainable params: 0\n","_________________________________________________________________\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_7 (InputLayer)         (None, 230, 230, 1)       0         \n","_________________________________________________________________\n","conv2d_4 (Conv2D)            (None, 230, 230, 12)      1212      \n","_________________________________________________________________\n","dense_12 (Dense)             (None, 230, 230, 512)     6656      \n","_________________________________________________________________\n","dense_13 (Dense)             (None, 230, 230, 1)       513       \n","=================================================================\n","Total params: 8,381\n","Trainable params: 8,381\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n","  'Discrepancy between trainable weights and collected trainable'\n","/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n","  'Discrepancy between trainable weights and collected trainable'\n"],"name":"stderr"},{"output_type":"stream","text":["@       0:\tAccuracy:  50%\tG-Loss: 14.493\tD-Loss:  8.053\tCombined: 22.546\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n","  'Discrepancy between trainable weights and collected trainable'\n"],"name":"stderr"},{"output_type":"stream","text":["@      50:\tAccuracy:  50%\tG-Loss:  4.915\tD-Loss:  7.912\tCombined: 12.827\n","@     100:\tAccuracy:  50%\tG-Loss:  3.948\tD-Loss:  1.768\tCombined:  5.716\n","@     150:\tAccuracy:  50%\tG-Loss:  3.773\tD-Loss:  1.499\tCombined:  5.271\n","@     200:\tAccuracy:  50%\tG-Loss:  3.698\tD-Loss:  1.343\tCombined:  5.041\n","@     250:\tAccuracy:  50%\tG-Loss:  3.606\tD-Loss:  1.207\tCombined:  4.813\n","@     300:\tAccuracy:  50%\tG-Loss:  3.497\tD-Loss:  1.062\tCombined:  4.559\n","@     350:\tAccuracy:  50%\tG-Loss:  3.433\tD-Loss:  0.922\tCombined:  4.355\n","@     400:\tAccuracy:  50%\tG-Loss:  3.308\tD-Loss:  0.800\tCombined:  4.108\n","@     450:\tAccuracy:  50%\tG-Loss:  3.200\tD-Loss:  0.705\tCombined:  3.906\n","@     500:\tAccuracy:  50%\tG-Loss:  3.013\tD-Loss:  0.641\tCombined:  3.653\n","@     550:\tAccuracy:  50%\tG-Loss:  2.737\tD-Loss:  0.585\tCombined:  3.322\n","@     600:\tAccuracy:  50%\tG-Loss:  1.959\tD-Loss:  0.574\tCombined:  2.533\n","@     650:\tAccuracy:  50%\tG-Loss:  1.657\tD-Loss:  0.592\tCombined:  2.249\n","@     700:\tAccuracy:  50%\tG-Loss:  1.154\tD-Loss:  0.643\tCombined:  1.797\n","@     750:\tAccuracy:  50%\tG-Loss:  1.028\tD-Loss:  0.634\tCombined:  1.662\n","@     800:\tAccuracy:  90%\tG-Loss:  1.008\tD-Loss:  0.648\tCombined:  1.656\n","@     850:\tAccuracy:  86%\tG-Loss:  0.854\tD-Loss:  0.700\tCombined:  1.554\n","@     900:\tAccuracy:  65%\tG-Loss:  0.849\tD-Loss:  0.758\tCombined:  1.606\n","@     950:\tAccuracy:  86%\tG-Loss:  0.837\tD-Loss:  0.681\tCombined:  1.518\n","@    1000:\tAccuracy:  83%\tG-Loss:  0.721\tD-Loss:  0.717\tCombined:  1.438\n","@    1050:\tAccuracy:  56%\tG-Loss:  0.728\tD-Loss:  0.721\tCombined:  1.449\n","@    1100:\tAccuracy:  84%\tG-Loss:  0.727\tD-Loss:  0.703\tCombined:  1.430\n","@    1150:\tAccuracy:  84%\tG-Loss:  0.734\tD-Loss:  0.678\tCombined:  1.412\n","@    1200:\tAccuracy:  41%\tG-Loss:  0.714\tD-Loss:  0.724\tCombined:  1.438\n","@    1250:\tAccuracy:  45%\tG-Loss:  0.707\tD-Loss:  0.718\tCombined:  1.426\n","@    1300:\tAccuracy:  51%\tG-Loss:  0.756\tD-Loss:  0.706\tCombined:  1.462\n","@    1350:\tAccuracy:  41%\tG-Loss:  0.696\tD-Loss:  0.724\tCombined:  1.420\n","@    1400:\tAccuracy:  79%\tG-Loss:  0.689\tD-Loss:  0.696\tCombined:  1.385\n","@    1450:\tAccuracy:  42%\tG-Loss:  0.695\tD-Loss:  0.702\tCombined:  1.396\n","@    1500:\tAccuracy:  65%\tG-Loss:  0.709\tD-Loss:  0.693\tCombined:  1.402\n","@    1550:\tAccuracy:  40%\tG-Loss:  0.691\tD-Loss:  0.722\tCombined:  1.412\n","@    1600:\tAccuracy:  42%\tG-Loss:  0.694\tD-Loss:  0.721\tCombined:  1.414\n","@    1650:\tAccuracy:  44%\tG-Loss:  0.691\tD-Loss:  0.717\tCombined:  1.408\n","@    1700:\tAccuracy:  23%\tG-Loss:  0.689\tD-Loss:  0.769\tCombined:  1.459\n","@    1750:\tAccuracy:  43%\tG-Loss:  0.704\tD-Loss:  0.716\tCombined:  1.420\n","@    1800:\tAccuracy:  43%\tG-Loss:  0.691\tD-Loss:  0.714\tCombined:  1.405\n","@    1850:\tAccuracy:  39%\tG-Loss:  0.690\tD-Loss:  0.725\tCombined:  1.415\n","@    1900:\tAccuracy:  45%\tG-Loss:  0.695\tD-Loss:  0.711\tCombined:  1.406\n","@    1950:\tAccuracy:  47%\tG-Loss:  0.692\tD-Loss:  0.726\tCombined:  1.418\n","@    2000:\tAccuracy:  42%\tG-Loss:  0.693\tD-Loss:  0.716\tCombined:  1.409\n","@    2050:\tAccuracy:  45%\tG-Loss:  0.706\tD-Loss:  0.702\tCombined:  1.408\n","@    2100:\tAccuracy:  42%\tG-Loss:  0.696\tD-Loss:  0.700\tCombined:  1.396\n","@    2150:\tAccuracy:  40%\tG-Loss:  0.696\tD-Loss:  0.721\tCombined:  1.417\n","@    2200:\tAccuracy:  41%\tG-Loss:  0.695\tD-Loss:  0.716\tCombined:  1.411\n","@    2250:\tAccuracy:  42%\tG-Loss:  0.700\tD-Loss:  0.714\tCombined:  1.414\n","@    2300:\tAccuracy:  44%\tG-Loss:  0.698\tD-Loss:  0.711\tCombined:  1.409\n","@    2350:\tAccuracy:  46%\tG-Loss:  0.701\tD-Loss:  0.710\tCombined:  1.411\n","@    2400:\tAccuracy:  43%\tG-Loss:  0.706\tD-Loss:  0.710\tCombined:  1.416\n","@    2450:\tAccuracy:  38%\tG-Loss:  0.702\tD-Loss:  0.703\tCombined:  1.405\n","@    2500:\tAccuracy:  47%\tG-Loss:  0.704\tD-Loss:  0.714\tCombined:  1.418\n","@    2550:\tAccuracy:  41%\tG-Loss:  0.702\tD-Loss:  0.711\tCombined:  1.413\n","@    2600:\tAccuracy:  43%\tG-Loss:  0.703\tD-Loss:  0.711\tCombined:  1.414\n","@    2650:\tAccuracy:  49%\tG-Loss:  0.723\tD-Loss:  0.710\tCombined:  1.432\n","@    2700:\tAccuracy:  44%\tG-Loss:  0.704\tD-Loss:  0.707\tCombined:  1.412\n","@    2750:\tAccuracy:  86%\tG-Loss:  0.707\tD-Loss:  0.710\tCombined:  1.417\n","@    2800:\tAccuracy:  46%\tG-Loss:  0.706\tD-Loss:  0.699\tCombined:  1.405\n","@    2850:\tAccuracy:  53%\tG-Loss:  0.706\tD-Loss:  0.706\tCombined:  1.412\n","@    2900:\tAccuracy:  53%\tG-Loss:  0.708\tD-Loss:  0.703\tCombined:  1.412\n","@    2950:\tAccuracy:  54%\tG-Loss:  0.709\tD-Loss:  0.712\tCombined:  1.421\n","@    3000:\tAccuracy:  58%\tG-Loss:  0.708\tD-Loss:  0.698\tCombined:  1.407\n","@    3050:\tAccuracy:  53%\tG-Loss:  0.709\tD-Loss:  0.706\tCombined:  1.415\n","@    3100:\tAccuracy:  55%\tG-Loss:  0.711\tD-Loss:  0.704\tCombined:  1.415\n","@    3150:\tAccuracy:  53%\tG-Loss:  0.711\tD-Loss:  0.703\tCombined:  1.414\n","@    3200:\tAccuracy:  55%\tG-Loss:  0.711\tD-Loss:  0.703\tCombined:  1.414\n","@    3250:\tAccuracy:  55%\tG-Loss:  0.712\tD-Loss:  0.705\tCombined:  1.416\n","@    3300:\tAccuracy:  53%\tG-Loss:  0.712\tD-Loss:  0.702\tCombined:  1.414\n","@    3350:\tAccuracy:  54%\tG-Loss:  0.716\tD-Loss:  0.702\tCombined:  1.418\n","@    3400:\tAccuracy:  54%\tG-Loss:  0.714\tD-Loss:  0.701\tCombined:  1.415\n","@    3450:\tAccuracy:  55%\tG-Loss:  0.714\tD-Loss:  0.702\tCombined:  1.417\n","@    3500:\tAccuracy:  56%\tG-Loss:  0.716\tD-Loss:  0.693\tCombined:  1.409\n","@    3550:\tAccuracy:  54%\tG-Loss:  0.716\tD-Loss:  0.697\tCombined:  1.413\n","@    3600:\tAccuracy:  56%\tG-Loss:  0.718\tD-Loss:  0.701\tCombined:  1.419\n","@    3650:\tAccuracy:  56%\tG-Loss:  0.718\tD-Loss:  0.698\tCombined:  1.416\n","@    3700:\tAccuracy:  62%\tG-Loss:  0.718\tD-Loss:  0.712\tCombined:  1.430\n","@    3750:\tAccuracy:  58%\tG-Loss:  0.719\tD-Loss:  0.699\tCombined:  1.418\n","@    3800:\tAccuracy:  54%\tG-Loss:  0.719\tD-Loss:  0.696\tCombined:  1.415\n","@    3850:\tAccuracy:  54%\tG-Loss:  0.721\tD-Loss:  0.695\tCombined:  1.416\n","@    3900:\tAccuracy:  57%\tG-Loss:  0.721\tD-Loss:  0.690\tCombined:  1.411\n","@    3950:\tAccuracy:  54%\tG-Loss:  0.721\tD-Loss:  0.696\tCombined:  1.417\n","@    4000:\tAccuracy:  56%\tG-Loss:  0.722\tD-Loss:  0.692\tCombined:  1.414\n","@    4050:\tAccuracy:  54%\tG-Loss:  0.722\tD-Loss:  0.693\tCombined:  1.415\n","@    4100:\tAccuracy:  57%\tG-Loss:  0.722\tD-Loss:  0.689\tCombined:  1.411\n","@    4150:\tAccuracy:  54%\tG-Loss:  0.722\tD-Loss:  0.694\tCombined:  1.416\n","@    4200:\tAccuracy:  57%\tG-Loss:  0.724\tD-Loss:  0.690\tCombined:  1.414\n","@    4250:\tAccuracy:  56%\tG-Loss:  0.724\tD-Loss:  0.691\tCombined:  1.414\n","@    4300:\tAccuracy:  56%\tG-Loss:  0.731\tD-Loss:  0.691\tCombined:  1.422\n","@    4350:\tAccuracy:  57%\tG-Loss:  0.725\tD-Loss:  0.690\tCombined:  1.415\n","@    4400:\tAccuracy:  65%\tG-Loss:  0.725\tD-Loss:  0.687\tCombined:  1.412\n","@    4450:\tAccuracy:  58%\tG-Loss:  0.725\tD-Loss:  0.688\tCombined:  1.413\n","@    4500:\tAccuracy:  57%\tG-Loss:  0.726\tD-Loss:  0.687\tCombined:  1.414\n","@    4550:\tAccuracy:  58%\tG-Loss:  0.727\tD-Loss:  0.684\tCombined:  1.411\n","@    4600:\tAccuracy:  57%\tG-Loss:  0.728\tD-Loss:  0.687\tCombined:  1.415\n","@    4650:\tAccuracy:  58%\tG-Loss:  0.728\tD-Loss:  0.685\tCombined:  1.413\n","@    4700:\tAccuracy:  54%\tG-Loss:  0.728\tD-Loss:  0.688\tCombined:  1.416\n","@    4750:\tAccuracy:  58%\tG-Loss:  0.729\tD-Loss:  0.684\tCombined:  1.412\n","@    4800:\tAccuracy:  55%\tG-Loss:  0.732\tD-Loss:  0.687\tCombined:  1.418\n","@    4850:\tAccuracy:  55%\tG-Loss:  0.730\tD-Loss:  0.686\tCombined:  1.416\n","@    4900:\tAccuracy:  66%\tG-Loss:  0.730\tD-Loss:  0.676\tCombined:  1.406\n","@    4950:\tAccuracy:  59%\tG-Loss:  0.731\tD-Loss:  0.681\tCombined:  1.412\n","@    5000:\tAccuracy:  62%\tG-Loss:  0.731\tD-Loss:  0.678\tCombined:  1.409\n","@    5050:\tAccuracy:  59%\tG-Loss:  0.732\tD-Loss:  0.680\tCombined:  1.412\n","@    5100:\tAccuracy:  59%\tG-Loss:  0.733\tD-Loss:  0.679\tCombined:  1.412\n","@    5150:\tAccuracy:  59%\tG-Loss:  0.734\tD-Loss:  0.679\tCombined:  1.413\n","@    5200:\tAccuracy:  71%\tG-Loss:  0.736\tD-Loss:  0.663\tCombined:  1.399\n","@    5250:\tAccuracy:  57%\tG-Loss:  0.736\tD-Loss:  0.681\tCombined:  1.418\n","@    5300:\tAccuracy:  57%\tG-Loss:  0.738\tD-Loss:  0.679\tCombined:  1.418\n","@    5350:\tAccuracy:  62%\tG-Loss:  0.737\tD-Loss:  0.674\tCombined:  1.411\n","@    5400:\tAccuracy:  56%\tG-Loss:  0.737\tD-Loss:  0.682\tCombined:  1.419\n","@    5450:\tAccuracy:  62%\tG-Loss:  0.737\tD-Loss:  0.674\tCombined:  1.411\n","@    5500:\tAccuracy:  70%\tG-Loss:  0.738\tD-Loss:  0.660\tCombined:  1.398\n","@    5550:\tAccuracy:  55%\tG-Loss:  0.739\tD-Loss:  0.684\tCombined:  1.423\n","@    5600:\tAccuracy:  60%\tG-Loss:  0.742\tD-Loss:  0.673\tCombined:  1.416\n","@    5650:\tAccuracy:  57%\tG-Loss:  0.740\tD-Loss:  0.677\tCombined:  1.418\n","@    5700:\tAccuracy:  56%\tG-Loss:  0.741\tD-Loss:  0.679\tCombined:  1.420\n","@    5750:\tAccuracy:  60%\tG-Loss:  0.741\tD-Loss:  0.672\tCombined:  1.413\n","@    5800:\tAccuracy:  56%\tG-Loss:  0.741\tD-Loss:  0.680\tCombined:  1.421\n","@    5850:\tAccuracy:  59%\tG-Loss:  0.741\tD-Loss:  0.671\tCombined:  1.412\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-3b0d43b78634>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    260\u001b[0m     \u001b[0;31m# Train the GAN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m     \u001b[0mgan\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGAN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m     \u001b[0mgan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_interval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSAMPLE_INTERVAL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-8-3b0d43b78634>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, epochs, batch_size, sample_interval)\u001b[0m\n\u001b[1;32m    208\u001b[0m                 \u001b[0;31m# Train the generator (to have the discriminator label samples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;31m# as valid)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m                 \u001b[0mg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcombined\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m                 \u001b[0;31m# Train the generator (to have the discriminator label samples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"Tbia2zHZdFRU","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}